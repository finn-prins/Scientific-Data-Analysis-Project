{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 11: Twitter Sentiment and Bitcoin Prices\n",
    "\n",
    "**Group Members:**  Andrey Bartashevich (14586517), Finn Prins (13458434), Duco Trompert (14591227)\n",
    "\n",
    "# Research Question:\n",
    " \n",
    "**Is there a correlation between Twitter (X) posts and Bitcoin price fluctuations or trading volume?**\n",
    "\n",
    "# Hypothesis: \n",
    "**Null hypothesis:** There is no correlation between Twitter (X) posts and changes in Bitcoin prices or trading volume.\n",
    "\n",
    "**Alternative Hypothesis:** Twitter (X) posts are correlated with changes in Bitcoin prices and trading volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitcoin dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First btc price is 2012-01-01\n",
    "Last btc price is 2024-11-28\n",
    "\n",
    "First tweet is 2007-04-19\n",
    "Last tweet is 2019-11-23\n",
    "\n",
    "Data from 2012-01-01 to 2019-11-23 is valuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date interval\n",
    "start_day = \"2012-01-01\"\n",
    "end_day = \"2019-11-23\"\n",
    "\n",
    "# Open bitcoin csv\n",
    "bitcoin = pd.read_csv('data/btcusd_1-min_data.csv')\n",
    "# Renaming timestamp, Close, and Volume columns\n",
    "bitcoin.rename(columns={'Timestamp': 'date', 'Close': 'price', 'Volume': 'volume'}, inplace=True)\n",
    "# Make the data column datetime type\n",
    "bitcoin['date'] = pd.to_datetime(bitcoin['date'], unit='s')\n",
    "# Convert to datetime and filter by date interval\n",
    "bitcoin = bitcoin[(bitcoin['date'] >= start_day) & (bitcoin['date'] <= end_day)]\n",
    "# Convert to daily granularity\n",
    "bitcoin['date'] = pd.to_datetime(bitcoin['date']).dt.date\n",
    "bitcoin = bitcoin.groupby('date').agg(\n",
    "    first_price=('price', 'first'),  # First price of the day\n",
    "    last_price=('price', 'last'),   # Last price of the day\n",
    "    price=('price', 'last'),   # Last closing price of the day\n",
    "    volume=('volume', 'sum')   # Total daily volume\n",
    ").reset_index()\n",
    "bitcoin['change'] = bitcoin['last_price'] - bitcoin['first_price']\n",
    "bitcoin['change'] = bitcoin['change'].fillna(0)\n",
    "bitcoin = bitcoin[['date', 'price', 'change', 'volume']]\n",
    "\n",
    "\n",
    "# Print processed Bitcoin data\n",
    "print(f\"Length: {len(bitcoin)}\")\n",
    "print(bitcoin.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open twitter csv\n",
    "tweet = pd.read_csv('data/tweets_sentiment.csv')\n",
    "# Sort the dataset\n",
    "tweet = tweet.sort_values('date').reset_index(drop=True)\n",
    "# Make the data column datetime type\n",
    "tweet['date'] = pd.to_datetime(tweet['date'], format='%Y-%m-%d')\n",
    "# Convert to datetime and filter by date interval\n",
    "tweet = tweet[(tweet['date'] >= start_day) & (tweet['date'] <= end_day)]\n",
    "\n",
    "# Print processed Twitter data\n",
    "print(f\"Length: {len(tweet)}\")\n",
    "print(tweet.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalized total impressions and sentiment calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions = tweet.groupby('date').agg(\n",
    "    likes=('likes', 'sum'),  # Sum of likes per day\n",
    "    replies=('replies', 'sum'),  # Sum of replies per day\n",
    "    retweets=('retweets', 'sum'),  # Sum of retweets per day\n",
    ").reset_index()\n",
    "\n",
    "# Calculate average likes, replies, and retweets\n",
    "avg_likes = tweet['likes'].mean()\n",
    "avg_replies = tweet['replies'].mean()\n",
    "avg_retweets = tweet['retweets'].mean()\n",
    "\n",
    "# Print average likes, replies, and retweets\n",
    "print(f\"Average likes: {avg_likes}\")\n",
    "print(f\"Average replies: {avg_replies}\")\n",
    "print(f\"Average retweets: {avg_retweets}\")\n",
    "\n",
    "# Add normalized total impressions\n",
    "impressions['total'] = 1 / avg_likes * impressions['likes'] + \\\n",
    "                       1 / avg_replies * impressions['replies'] + \\\n",
    "                       1 / avg_retweets * impressions['retweets']\n",
    "\n",
    "tweet['sentiment'] = (tweet['likes'] / avg_likes +\n",
    "                      tweet['replies'] / avg_replies +\n",
    "                      tweet['retweets'] / avg_retweets) * tweet['sentiment']\n",
    "\n",
    "# Group sentiment by date and assign to impressions\n",
    "impressions['sentiment'] = tweet.groupby('date')['sentiment'].sum().values\n",
    "\n",
    "\n",
    "print(f\"Length: {len(impressions)}\")\n",
    "print(impressions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitcoin Metrics (impressions, volume, average price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time conversion\n",
    "impressions['date'] = pd.to_datetime(impressions['date'])\n",
    "#only taking year for date\n",
    "impressions['year'] = impressions['date'].dt.year\n",
    "bitcoin['date'] = pd.to_datetime(bitcoin['date'])\n",
    "\n",
    "# calculations of yearly matrices\n",
    "year_impressions = impressions.groupby('year')['total'].sum().reset_index()\n",
    "year_volume = bitcoin.groupby(bitcoin['date'].dt.year)['volume'].sum().reset_index()\n",
    "year_price = bitcoin.groupby(bitcoin['date'].dt.year)['price'].mean().reset_index()\n",
    "\n",
    "# changing the name of date on year and price\n",
    "year_volume = year_volume.rename(columns={'date': 'year'})\n",
    "year_price = year_price.rename(columns={'date': 'year'})\n",
    "\n",
    "#plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "ax2 = ax1.twinx()\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "# prevent overlap on y axis\n",
    "ax3.spines['right'].set_position(('outward', 60))\n",
    "# impressions\n",
    "bars_impressions = ax1.bar(year_impressions['year'], year_impressions['total'],  alpha=0.4, color='blue', label='impressions')\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "#impression bar labels\n",
    "for i, v in enumerate(year_impressions['total']):\n",
    "    ax1.text(year_impressions['year'][i], v, round(v, 2), ha='center', va='bottom')\n",
    "\n",
    "# bitcoin price\n",
    "line = ax2.plot(year_price['year'], year_price['price'],color='red', label='price')\n",
    "\n",
    "# volume\n",
    "bars_volume = ax3.bar(year_volume['year'], year_volume['volume'], alpha=0.4, color='green', label='volume')\n",
    "ax3.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "#volume bar labels (using scientific notation for visual interpretation)\n",
    "for i, v in enumerate(year_volume['volume']):\n",
    "    ax3.text(year_volume['year'][i], v, f'{v:.2e}', ha='center', va='bottom', color='green')\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Total Impressions', color='blue', alpha=0.7)\n",
    "ax2.set_ylabel('Average Price', color='red')\n",
    "ax3.set_ylabel('Volume', color='green')\n",
    "plt.title('Yearly Bitcoin metrics')\n",
    "# legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2 + lines3, labels1 + labels2 + labels3, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis (only english text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for result consistency\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# englsih language checker\n",
    "def is_english(text):\n",
    "    try:\n",
    "        # empty or nan line checker\n",
    "        if pd.isna(text) or text.strip() == '':\n",
    "            return False\n",
    "        # using detect function to find english text\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "         return False\n",
    "\n",
    "\n",
    "# sentiment analysis using vader library\n",
    "def vader_sentiment(text):\n",
    "        #initializing vader module\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        # sentiment scores (compound) from -1 to 1\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        # calculation of sentiment based on the compund score\n",
    "        # positive\n",
    "        if scores['compound'] >= 0.05:\n",
    "            sentiment = 1\n",
    "        # negative\n",
    "        elif scores['compound'] <= -0.05:\n",
    "            sentiment = -1\n",
    "        # neutral\n",
    "        else:\n",
    "            sentiment = 0\n",
    "        return {'sentiment':sentiment, 'compound':scores['compound']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SHould we include the explanation that sentiment analysis was run using ab external python file, since the notebook, could't handle large size of the data???***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using previously cleaned data from the sentiment analysis and taking 6 mill rows\n",
    "tweet_sentiment = pd.read_csv('data/tweets_sentiment.csv',nrows=6_000_000)\n",
    "\n",
    "#cleaning the text using specific characters found in the tweets\n",
    "def clean_text(s):\n",
    "    s = re.sub(r'http\\S+', '', s)\n",
    "    s = re.sub('(RT|via)((?:\\\\b\\\\W*@\\\\w+)+)', ' ', s)\n",
    "    s = re.sub(r'@\\S+', '', s)\n",
    "    s = re.sub('&amp', ' ', s)\n",
    "    s = re.sub('com', ' ', s)\n",
    "    s = re.sub(r'[^\\x00-\\x7F]+', '', s)\n",
    "    s = re.sub(r'[\\u2022\\u2023\\u2043\\u204C\\u204D\\u2219\\u25D8\\u25E6\\u2619\\u2043\\u25AA\\u25FB]', '', s)\n",
    "    return s\n",
    "\n",
    "# dataframe copy\n",
    "processed_tweets = tweet_sentiment[['text']].copy()\n",
    "# text cleaning\n",
    "processed_tweets['cleaned_text'] = processed_tweets['text'].apply(clean_text)\n",
    "# string with processed text\n",
    "processed_text = ' '.join(processed_tweets['cleaned_text'].astype(str).str.lower())\n",
    "\n",
    "# worldcloud visual\n",
    "wordcloud = WordCloud(\n",
    "    width=1200,\n",
    "    height=700,\n",
    "    collocations=True,\n",
    "    relative_scaling=0.4,\n",
    "    stopwords=set(stopwords.words('english'))\n",
    ").generate(processed_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stationary(series):\n",
    "    result = adfuller(series)\n",
    "\n",
    "    if result[0] < result[4]['5%']:\n",
    "        return True, result[0]\n",
    "    else:\n",
    "        return False, result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log impressions and log bitcoin price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "date_range = pd.date_range(start=start_day, end=end_day)\n",
    "date_df = pd.DataFrame({'date': date_range.date})\n",
    "date_df['date'] = pd.to_datetime(date_df['date'])\n",
    "\n",
    "impressions['date'] = pd.to_datetime(impressions['date'])\n",
    "impressions = pd.merge(date_df, impressions, on='date', how='left')\n",
    "impressions = impressions.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Fix obvious anomalies\n",
    "impressions['total'].iloc[-1] = impressions['total'].iloc[-2]\n",
    "impressions['sentiment'].iloc[-1] = impressions['sentiment'].iloc[-2]\n",
    "\n",
    "bitcoin['volume'].iloc[-1] = bitcoin['volume'].iloc[-2]\n",
    "for i in [20, 1101, 1102, 1103, 1104]:\n",
    "    bitcoin['volume'].iloc[i] = bitcoin['volume'].iloc[i - 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bitcoin['date'] = pd.to_datetime(bitcoin['date'])\n",
    "bitcoin = pd.merge(date_df, bitcoin, on='date', how='left')\n",
    "bitcoin = bitcoin.fillna(0)\n",
    "\n",
    "# Adding 1 to avoid log(0) and interpolting for missing values\n",
    "log_price = np.log(bitcoin['price'] + 1).interpolate(method='linear')\n",
    "log_volume = np.log(bitcoin['volume'] + 1).interpolate(method='linear')\n",
    "log_change = np.log(abs(bitcoin['change']) + 1) * np.sign(bitcoin['change'])\n",
    "log_impressions = np.log(impressions['total'] + 1).interpolate(method='linear')\n",
    "log_sentiment = np.log(impressions['sentiment'] + 1).interpolate(method='linear')\n",
    "\n",
    "adf_price = adfuller(log_price)\n",
    "adf_volume = adfuller(log_volume)\n",
    "adf_change = adfuller(log_change)\n",
    "adf_impressions = adfuller(log_impressions)\n",
    "adf_sentiment = adfuller(log_sentiment)\n",
    "\n",
    "print(f\"Price ADF: {adf_price[0]}, cutoff: {adf_price[4]}\")\n",
    "print(f\"Volume ADF: {adf_volume[0]}, cutoff: {adf_volume[4]}\")\n",
    "print(f\"Change ADF: {adf_change[0]}, cutoff: {adf_change[4]}\")\n",
    "print(f\"Impressions ADF: {adf_impressions[0]}, cutoff: {adf_impressions[4]}\")\n",
    "print(f\"Sentiment ADF: {adf_sentiment[0]}, cutoff: {adf_sentiment[4]}\")\n",
    "\n",
    "\n",
    "# Log Bitcoin price vs log total impressions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_impressions, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.plot(date_range, log_price, label='Log Bitcoin Daily Price', color='#1f77b4')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"impressions_vs_price.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Log Bitcoin volume vs log total impressions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_impressions, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.plot(date_range, log_volume, label='Log Bitcoin Daily Volume', color='#1f77b4')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"impressions_vs_volume.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Bitcoin change vs log total impressions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_change, label='Bitcoin Daily Change', color='#1f77b4')\n",
    "plt.plot(date_range, log_impressions, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"impressions_vs_change.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Log Bitcoin price vs log sentiment magnitude\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_sentiment, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.plot(date_range, log_price, label='Log Bitcoin Daily Price', color='#1f77b4')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Log Bitcoin volume vs log sentiment magnitude\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_sentiment, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.plot(date_range, log_volume, label='Log Bitcoin Daily Volume', color='#1f77b4')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Bitcoin change vs log sentiment magnitude\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(date_range, log_change, label='Bitcoin Daily Change', color='#1f77b4')\n",
    "plt.plot(date_range, log_sentiment, label='Log Daily Normalized Total Impressions', color='#ff7f0e')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson correlation coefficient**\n",
    "\n",
    "The Pearson correlation coefficient (denoted as $r$) is calculated as:\n",
    "\n",
    "$r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}$\n",
    "\n",
    "Where:\n",
    "- $\\text{Cov}(X, Y)$ is the covariance between $X$ and $Y$, which measures how much the two variables change together.\n",
    "- $\\sigma_X$ and $\\sigma_Y$ are the standard deviations of $X$ and $Y$, which measure the variability in each variable.\n",
    "\n",
    "Key points:\n",
    "- Assumes a linear relationship and requires continuous, normally distributed variables.\n",
    "- Sensitive to outliers.\n",
    "- $r = 1$ shows a perfect positive linear correlation.\n",
    "- $r = -1$ shows a perfect negative linear correlation.\n",
    "- $r = 0$ shows no linear correaltion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean\n",
    "def mean(X):\n",
    "    return sum(X) / len(X)\n",
    "\n",
    "\n",
    "# Calculate standard deviation\n",
    "def standard_deviation(X):\n",
    "    n = len(X)\n",
    "    mean_X = mean(X)\n",
    "\n",
    "    squared_differences = [(x - mean_X)**2 for x in X]\n",
    "\n",
    "    variance = sum(squared_differences) / n\n",
    "\n",
    "    std_dev = variance**0.5\n",
    "\n",
    "    return std_dev\n",
    "\n",
    "\n",
    "# Calculate covariance\n",
    "def covariance(X, Y):\n",
    "    mean_X = mean(X)\n",
    "    mean_Y = mean(Y)\n",
    "\n",
    "    deviations_product = [(x - mean_X) * (y - mean_Y) for x, y in zip(X, Y)]\n",
    "\n",
    "    covariance = sum(deviations_product) / len(X)\n",
    "\n",
    "    return covariance\n",
    "\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "def pearson_correlation(X, Y):\n",
    "    covariance_XY = covariance(X, Y)\n",
    "    std_X = standard_deviation(X)\n",
    "    std_Y = standard_deviation(Y)\n",
    "    return covariance_XY / (std_X * std_Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print several Pearson correlation coefficients\n",
    "pcc = pearson_correlation(log_price, log_impressions)\n",
    "print(f\"The Pearson correlation coefficient between the logarithm of Bitcoin price and the logarithm of normalized total impressions is:\\n{pcc}\")\n",
    "\n",
    "pcc = pearson_correlation(log_volume, log_impressions)\n",
    "print(f\"The Pearson correlation coefficient between the logarithm of Bitcoin volume and the logarithm of normalized total impressions is:\\n{pcc}\")\n",
    "\n",
    "pcc = pearson_correlation(log_change, log_impressions)\n",
    "print(f\"The Pearson correlation coefficient between the Bitcoin change and the logarithm of normalized total impressions is:\\n{pcc}\")\n",
    "\n",
    "pcc = pearson_correlation(log_price, log_sentiment)\n",
    "print(f\"The Pearson correlation coefficient between the logarithm of Bitcoin price and the logarithm of normalized sentiment magnitude is:\\n{pcc}\")\n",
    "\n",
    "pcc = pearson_correlation(log_volume, log_sentiment)\n",
    "print(f\"The Pearson correlation coefficient between the logarithm of Bitcoin volume and the logarithm of normalized sentiment magnitude is:\\n{pcc}\")\n",
    "\n",
    "pcc = pearson_correlation(log_change, log_sentiment)\n",
    "print(f\"The Pearson correlation coefficient between the Bitcoin change and the logarithm of normalized sentiment magnitude is:\\n{pcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spearman Rank Correlation**\n",
    "\n",
    "The Spearman rank correlation coefficient (denoted as $\\rho$) measures the strength and direction of a monotonic relationship between two variables.\n",
    "\n",
    "$\\rho = 1 - \\frac{6 \\sum d_i^2}{n (n^2 - 1)}$\n",
    "\n",
    "Where:\n",
    "- $d_i$ is the difference between the ranks of corresponding values in $X$ and $Y$.\n",
    "- $n$ is the number of data points.\n",
    "\n",
    "Key points:\n",
    "- Converts the data to ranks, making it a **non-parametric measure**.\n",
    "- $\\rho = 1$: perfect positive monotonic relationship.\n",
    "- $\\rho = -1$: perfect negative monotonic relationship.\n",
    "- $\\rho = 0$: no monotonic relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the data\n",
    "def rank(data):\n",
    "    return [sorted(data).index(x) + 1 for x in data]\n",
    "\n",
    "\n",
    "# Calculate Spearman rank correlation\n",
    "def spearman_correlation(X, Y):\n",
    "    n = len(X)\n",
    "    rank_X = rank(X)\n",
    "    rank_Y = rank(Y)\n",
    "    d_squared = [(rx - ry) ** 2 for rx, ry in zip(rank_X, rank_Y)]\n",
    "    rho = 1 - (6 * sum(d_squared)) / (n * (n**2 - 1))\n",
    "    return rho\n",
    "\n",
    "\n",
    "# Calculate and print several Spearman rank correlations\n",
    "src = spearman_correlation(log_price, log_impressions)\n",
    "print(f\"The Spearman rank correlations between the logarithm of Bitcoin price and the logarithm of normalized total impressions is:\\n{src}\")\n",
    "\n",
    "src = spearman_correlation(log_volume, log_impressions)\n",
    "print(f\"The Spearman rank correlations between the logarithm of Bitcoin volume and the logarithm of normalized total impressions is:\\n{src}\")\n",
    "\n",
    "src = spearman_correlation(log_change, log_impressions)\n",
    "print(f\"The Spearman rank correlations between the Bitcoin change and the logarithm of normalized total impressions is:\\n{src}\")\n",
    "\n",
    "src = spearman_correlation(log_price, log_sentiment)\n",
    "print(f\"The Spearman rank correlations between the logarithm of Bitcoin price and the logarithm of normalized sentiment magnitude is:\\n{src}\")\n",
    "\n",
    "src = spearman_correlation(log_volume, log_sentiment)\n",
    "print(f\"The Spearman rank correlations between the logarithm of Bitcoin volume and the logarithm of normalized sentiment magnitude is:\\n{src}\")\n",
    "\n",
    "src = spearman_correlation(log_change, log_sentiment)\n",
    "print(f\"The Spearman rank correlations between the Bitcoin change and the logarithm of normalized sentiment magnitude is:\\n{src}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kendall Tau Correlation**\n",
    "\n",
    "The Kendall Tau correlation (denoted as $\\tau$) evaluates the degree of concordance between two ranked variables.\n",
    "\n",
    "$\\tau = \\frac{C - D}{\\frac{1}{2}n(n-1)}$\n",
    "\n",
    "Where:\n",
    "- $C$ is the number of concordant pairs (pairs of points $(X_i, Y_i)$ and $(X_j, Y_j)$ where the order is the same).\n",
    "- $D$ is the number of discordant pairs (pairs of points where the order is reversed).\n",
    "- $n$ is the total number of points.\n",
    "\n",
    "Key points:\n",
    "- A **non-parametric measure** suited for ordinal data.\n",
    "- $\\tau = 1$: perfect agreement in ranks.\n",
    "- $\\tau = -1$: perfect disagreement in ranks.\n",
    "- $\\tau = 0$: no association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Kendall Tau correlation\n",
    "def kendall_tau(X, Y):\n",
    "    n = len(X)\n",
    "    concordant = 0\n",
    "    discordant = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if (X[i] - X[j]) * (Y[i] - Y[j]) > 0:\n",
    "                concordant += 1\n",
    "            elif (X[i] - X[j]) * (Y[i] - Y[j]) < 0:\n",
    "                discordant += 1\n",
    "    tau = (concordant - discordant) / (0.5 * n * (n - 1))\n",
    "    return tau\n",
    "\n",
    "\n",
    "# Calculate and print several Kendall Tau correlations\n",
    "ktc = kendall_tau(log_price, log_impressions)\n",
    "print(f\"The Kendall Tau correlation between the logarithm of Bitcoin price and the logarithm of normalized total impressions is:\\n{ktc}\")\n",
    "\n",
    "ktc = kendall_tau(log_volume, log_impressions)\n",
    "print(f\"The Kendall Tau correlation between the logarithm of Bitcoin volume and the logarithm of normalized total impressions is:\\n{ktc}\")\n",
    "\n",
    "ktc = kendall_tau(log_change, log_impressions)\n",
    "print(f\"The Kendall Tau correlation between the Bitcoin change and the logarithm of normalized total impressions is:\\n{ktc}\")\n",
    "\n",
    "ktc = kendall_tau(log_price, log_sentiment)\n",
    "print(f\"The Kendall Tau correlation between the logarithm of Bitcoin price and the logarithm of normalized sentiment magnitude is:\\n{ktc}\")\n",
    "\n",
    "ktc = kendall_tau(log_volume, log_sentiment)\n",
    "print(f\"The Kendall Tau correlation between the logarithm of Bitcoin volume and the logarithm of normalized sentiment magnitude is:\\n{ktc}\")\n",
    "\n",
    "ktc = kendall_tau(log_change, log_sentiment)\n",
    "print(f\"The Kendall Tau correlation between the Bitcoin change and the logarithm of normalized sentiment magnitude is:\\n{ktc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Correlation**\n",
    "\n",
    "Cross-correlation quantifies the similarity between two time series $X$ and $Y$ as a function of the lag (shift in time) between them.\n",
    "\n",
    "$r_\\text{lag} = \\frac{\\sum (X_t - \\bar{X})(Y_{t+\\text{lag}} - \\bar{Y})}{\\sqrt{\\sum (X_t - \\bar{X})^2 \\sum (Y_{t+\\text{lag}} - \\bar{Y})^2}}$\n",
    "\n",
    "Where:\n",
    "- $\\bar{X}$ and $\\bar{Y}$ are the means of $X$ and $Y$, respectively.\n",
    "- The numerator computes the covariance between $X$ and a lagged version of $Y$.\n",
    "\n",
    "Key points:\n",
    "- Often used in signal processing or time series analysis.\n",
    "- Determines how $X$ and $Y$ relate when one is shifted relative to the other.\n",
    "- Can identify lead-lag relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cross-Correlation\n",
    "def cross_correlation(X, Y, lag):\n",
    "    n = len(X)\n",
    "    mean_X = mean(X)\n",
    "    mean_Y = mean(Y)\n",
    "    if lag < 0:\n",
    "        lag = -lag\n",
    "        X, Y = Y[lag:], X[:-lag]\n",
    "    else:\n",
    "        X, Y = X[lag:], Y[:-lag]\n",
    "    numerator = sum((x - mean_X) * (y - mean_Y) for x, y in zip(X, Y))\n",
    "    denominator = (sum((x - mean_X) ** 2 for x in X) * sum((y - mean_Y) ** 2 for y in Y)) ** 0.5\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "# Plot several Kendall Tau correlations with different lags\n",
    "max_lag = 1000\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_price, log_impressions, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between logarithm of Bitcoin price and the logarithm of normalized total impressions vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_volume, log_impressions, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between logarithm of Bitcoin volume and the logarithm of normalized total impressions vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_change, log_impressions, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between Bitcoin change and the logarithm of normalized total impressions vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_price, log_sentiment, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between logarithm of Bitcoin price and the logarithm of normalized sentiment magnitude vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_volume, log_sentiment, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between logarithm of Bitcoin volume and the logarithm of normalized sentiment magnitude vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, max_lag + 1), [cross_correlation(log_change, log_sentiment, lag=lag) for lag in range(1, max_lag + 1)], label='Cross-Correlation')\n",
    "plt.title('Cross-correlation between Bitcoin change and the logarithm of normalized sentiment magnitude vs. lag ')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Granger Causality Test**\n",
    "\n",
    "Granger causality tests whether changes in one time series ($X$) can predict changes in another ($Y$), implying a directional causal relationship.\n",
    "\n",
    "Steps:\n",
    "1. Fit a restricted model: Regress $Y_t$ on its past values.\n",
    "2. Fit a full model: Regress $Y_t$ on its past values **and** past values of $X_t$.\n",
    "3. Compute the F-statistic:\n",
    "\n",
    "$F = \\frac{(RSS_r - RSS_f) / (k_f - k_r)}{RSS_f / (n - k_f)}$\n",
    "\n",
    "   Where:\n",
    "   - $RSS_r$: Residual sum of squares from the restricted model.\n",
    "   - $RSS_f$: Residual sum of squares from the full model.\n",
    "   - $k_r, k_f$: Number of parameters in restricted and full models.\n",
    "   - $n$: Number of observations.\n",
    "\n",
    "Key points:\n",
    "- More of a  statistical test rather than a measure of correlation.\n",
    "- Indicates whether $X$ \"Granger-causes\" $Y$ based on predictive power.\n",
    "- Does not prove true causation, only predictive influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "lag = 100\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_price, log_impressions], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between logarithm of Bitcoin price and the logarithm of normalized total impressions')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_volume, log_impressions], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between logarithm of Bitcoin volume and the logarithm of normalized total impressions')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_change, log_impressions], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between Bitcoin change and the logarithm of normalized total impressions')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_price, log_sentiment], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between logarithm of Bitcoin price and the logarithm of normalized sentiment magnitude')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_volume, log_sentiment], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between logarithm of Bitcoin volume and the logarithm of normalized sentiment magnitude')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "results = grangercausalitytests(pd.concat([log_change, log_sentiment], axis=1), maxlag=lag, verbose=False)\n",
    "p_values = [results[lag][0]['ssr_ftest'][1] for lag in range(1, lag + 1)]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, lag + 1), p_values, label='P-value')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (0.05)')\n",
    "plt.title('Granger Causality P-values across lags between Bitcoin change and the logarithm of normalized sentiment magnitude')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_test = pd.read_csv('data/tweets_sentiment.csv')\n",
    "\n",
    "tweet_test = tweet_test.sort_values('date').reset_index(drop=True)\n",
    "tweet_test['date'] = pd.to_datetime(tweet_test['date']).dt.date\n",
    "\n",
    "avg_likes = tweet_test['likes'].mean()\n",
    "avg_replies = tweet_test['replies'].mean()\n",
    "avg_retweets = tweet_test['retweets'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a date to impressions\n",
    "tweet_test['impressions'] = (tweet_test['likes'] / avg_likes + tweet_test['replies'] / avg_replies + tweet_test['retweets'] / avg_retweets)\n",
    "tweet_test['magnitude'] = tweet_test['impressions'] * tweet_test['sentiment']\n",
    "\n",
    "daily_impressions = tweet_test.groupby('date')['impressions'].sum().reset_index()\n",
    "daily_magnitude = tweet_test.groupby('date')['magnitude'].sum().reset_index()\n",
    "\n",
    "bitcoin_test = bitcoin[bitcoin['date'].isin(daily_impressions['date'])].reset_index(drop=True)\n",
    "\n",
    "log_bitcoin_change = np.log1p(bitcoin_test['change'].abs()) * np.sign(bitcoin_test['change'])\n",
    "log_magnitude = np.log1p(daily_magnitude['magnitude'].abs()) * np.sign(daily_magnitude['magnitude'])\n",
    "log_impressions = np.log1p(daily_impressions['impressions'].abs()) * np.sign(daily_impressions['impressions'])\n",
    "\n",
    "\n",
    "\n",
    "# do adfuller test on the data\n",
    "print(is_stationary(log_bitcoin_change))\n",
    "print(is_stationary(log_magnitude))\n",
    "print(is_stationary(log_impressions))\n",
    "print(is_stationary(daily_magnitude['magnitude']))\n",
    "print(is_stationary(bitcoin_test['change']))\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bitcoin_test['date'], log_magnitude, label='Log Magnitude', color='blue')\n",
    "plt.plot(bitcoin_test['date'], log_impressions, label='Log Impressions', color='red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(log_magnitude, log_bitcoin_change)\n",
    "plt.title('Log Daily Sentiment vs. Log Bitcoin Price Change')\n",
    "plt.xlabel('Log Magnitude')\n",
    "plt.ylabel('Log Bitcoin Price Change')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "linear_correlation = sp.stats.linregress(log_impressions, abs(log_bitcoin_change))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(log_impressions, abs(log_bitcoin_change))\n",
    "plt.plot(log_impressions, linear_correlation.intercept + linear_correlation.slope * log_impressions, color='red')\n",
    "plt.title(f'Log Impressions vs. Log Absolute Bitcoin Price Change, Pearson R = {linear_correlation.rvalue:.2f}')\n",
    "plt.xlabel('Impressions')\n",
    "plt.ylabel('Bitcoin Price Change')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(data1, data2, window_size, step_size, func):\n",
    "    if not isinstance(data1, (pd.Series, np.ndarray)) or not isinstance(data2, (pd.Series, np.ndarray)):\n",
    "        raise ValueError(\"Input data must be pandas Series or numpy arrays.\")\n",
    "\n",
    "    # Ensure data are numpy arrays for easier slicing if they are pandas Series\n",
    "    data_array1 = data1.values if isinstance(data1, pd.Series) else data1\n",
    "    data_array2 = data2.values if isinstance(data2, pd.Series) else data2\n",
    "\n",
    "    # Ensure both data arrays have the same length\n",
    "    if len(data_array1) != len(data_array2):\n",
    "        raise ValueError(\"Both data distributions must have the same length.\")\n",
    "\n",
    "    results = []\n",
    "    for start in range(0, len(data_array1) - window_size + 1, step_size):\n",
    "        window1 = data_array1[start:start + window_size]\n",
    "        window2 = data_array2[start:start + window_size]\n",
    "        if func:\n",
    "            results.append(func(window1, window2))\n",
    "\n",
    "    return results\n",
    "\n",
    "rolling_months = rolling_window(daily_magnitude['magnitude'], bitcoin_test['change'], window_size=30, step_size=30, func=sp.stats.pearsonr)\n",
    "rolling_months = [r[0] for r in rolling_months]\n",
    "rolling_months = np.array(rolling_months).reshape(-1, 12)\n",
    "\n",
    "rolling_quarters = rolling_window(daily_magnitude['magnitude'], bitcoin_test['change'], window_size=90, step_size=90, func=sp.stats.pearsonr)\n",
    "rolling_quarters = [r[0] for r in rolling_quarters]\n",
    "rolling_quarters = np.array(rolling_quarters).reshape(-1, 4)\n",
    "\n",
    "years = [2012 + i for i in range(rolling_months.shape[0])]\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.heatmap(rolling_months, cmap='coolwarm', cbar_kws={'label': 'Pearson Correlation Coefficient'})\n",
    "ax.set_yticklabels(years)\n",
    "ax.set_xticklabels(months)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Rolling Pearson Correlation Coefficient between Impressions and Bitcoin Price Change')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Year')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.heatmap(rolling_quarters, cmap='coolwarm', cbar_kws={'label': 'Pearson Correlation Coefficient'})\n",
    "ax.set_yticklabels(years)\n",
    "ax.set_xticklabels(quarters)\n",
    "plt.title('Rolling Pearson Correlation Coefficient between Impressions and Bitcoin Price Change')\n",
    "plt.xlabel('Quarters')\n",
    "plt.ylabel('Year')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
